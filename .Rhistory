"@@OCC@@")
write.csv(jobindex_2015, "jobindex_2015_20220924.csv")
library("lhs")
rm(list=ls())
set.seed(502)
n <- 500
x <- randomLHS(n,12)
#2018년
x[,1] <- qtruncnorm(x[,1],a=0, b=0.184, mean=0.184, sd=0.0092) #ROOF
x[,2] <- qtruncnorm(x[,2],a=0, b=0.513, mean=0.513, sd=0.02565) #WALL
x[,3] <- qtruncnorm(x[,3],a=0, b=0.321, mean=0.321, sd=0.01605) #FLOOR
x[,4] <- qtruncnorm(x[,4],a=0, b=1.76 , mean=1.76 , sd=0.088) #WIN
x[,5] <- qtruncnorm(x[,5],a=0, b=0.38 , mean=0.38  , sd=0.019) #SHGC
x[,6] <- qtruncnorm(x[,6],a=0, b=8.5  , mean=8.5  , sd=0.425) #LPD
x[,7] <- qtruncnorm(x[,7],a=3.2,b=Inf , mean=3.2  , sd=0.16) #HEATEFF
x[,8] <- qtruncnorm(x[,8],a=3.4,b=Inf , mean=3.4, sd=0.17) #COP
x[,9] <- qunif(x[,9],7.79,11) #EPD
x[,10] <- qunif(x[,10],18,24) #HSP
x[,11] <- qunif(x[,11],23,29) #CSP
x[,12] <- qunif(x[,12],0.05,0.07) #OCC
jobindex_2018 <- data.frame(x)
jobindex_2018 <- jobindex_2018[c(order(-jobindex_2018$X10)),]
colnames(jobindex_2018) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP",
"EPD","HSP", "CSP", "OCC")
CSP <- jobindex_2018$CSP
HSP <- jobindex_2018$HSP
plot(density(HSP),main="HSP")
plot(density(CSP),main="CSP")
HSP < CSP
all(HSP < CSP)
HSP <- sort(HSP, decreasing = TRUE)
min(CSP)
i <- 1
result=c()
while(i< n+1){
select.hsp <- HSP[i]
if( (select.hsp > min(CSP,na.rm = TRUE)) & (!is.na(select.hsp)) ){
select.csp <- sample(CSP[(CSP>select.hsp)&(!is.na(CSP))],1, replace = FALSE)
} else{
select.csp <- sample(CSP[!is.na(CSP)],1, replace = FALSE)
}
result = rbind(result,c(select.hsp,select.csp))
HSP[which(HSP == select.hsp)] = NA
CSP[which(CSP == select.csp)] = NA
i = i+1
if (length(CSP[!is.na(CSP)]) ==1){
select.csp <- CSP[!is.na(CSP)]
select.hsp <- HSP[!is.na(HSP)]
result  =rbind(result,c(select.hsp,select.csp))
HSP[which(HSP == select.hsp)] = NA
CSP[which(CSP == select.csp)] = NA
break
}
}
all(result[,1]<result[,2])
plot(density(result[,1]),main="HSP")
plot(density(result[,2]),main="CSP")
jobindex_2018$HSP <- result[,1]
jobindex_2018$CSP <- result[,2]
all(jobindex_2018$HSP < jobindex_2018$CSP)
write.csv(jobindex_2018, "jobindex_2018_20220924_변환전.csv")
##########################################################################
#ROOF, WALL, Floor 변환
jobindex_2018$ROOF <- ((1/jobindex_2018$ROOF) - 0.4 - 0.0095/0.16 - 0.0008/45.28 - 0.11)
jobindex_2018$WALL <- ((1/jobindex_2018$WALL) - 0.4 - 0.0254/0.72 - 0.0159/0.16 - 0.0159/0.16  - 0.11)
jobindex_2018$FLOOR <- ((1/jobindex_2018$FLOOR) - 0.1016/2.31 - 0.21648 - 0.11)
colnames(jobindex_2018) <- c("@@ROOF@@", "@@WALL@@","@@FLOOR@@" ,"@@WIN@@", "@@SHGC@@","@@LPD@@"
,"@@HEATEFF@@","@@COP@@", "@@EPD@@", "@@HSP@@",  "@@CSP@@",
"@@OCC@@")
write.csv(jobindex_2018, "jobindex_2018_20220924csv")
library(dplyr)
library(boot)
library(sensitivity)
library(lhs)
library(ggplot2)
getwd()
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/R_Sampling_Multicorrelation")
data_2006 <- read.csv("jobindex_2006_20220924_변환전.csv")
data_2009 <- read.csv("jobindex_2009_20220924_변환전.csv")
data_2012 <- read.csv("jobindex_2012_20220924_변환전.csv")
data_2015 <- read.csv("jobindex_2015_20220924_변환전.csv")
data_2018 <- read.csv("jobindex_2018_20220924_변환전.csv")
data_train <- rbind(data_2006,data_2009,data_2012,data_2015,data_2018)
View(data_2006)
data_train <- data_train[,c(2:13)]
colnames(data_train) <-  c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP",
"EPD","HSP", "CSP", "OCC", "TOTAL_E")
#######################################################################################################################
#다중 공선성 계산
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/multicollinearity_Graph_Excel")
VIF <- data.frame(VIF)
library(car)
VIF <- cor(data_train, method="pearson")
VIF <- data.frame(VIF)
View(VIF)
VIF
VIF <- data.frame(VIF)
write.csv(VIF, "MULTICORRELATION_Truncated_Distribution_20220924.csv")
vif(data_train)
library(corrgram)
png("CORRELATION_Color_Truncated_Distribution_20220924.png", width = 20000, height = 15000, res = 500)
correlation_color<-corrgram(data_train, upper.panel = panel.conf) #색상 표현
dev.off()
library(PerformanceAnalytics)
png("CORRELATION_Analysis_Truncated_Distribution_20220924.png", width = 20000, height = 15000, res = 500)
chart.Correlation(data_train, histogram = , pch="+")
dev.off()
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/R_Sampling_Multicorrelation")
data_2006 <- read.csv("jobindex_2006_20220924.csv")
data_2009 <- read.csv("jobindex_2009_20220924.csv")
data_2012 <- read.csv("jobindex_2012_20220924.csv")
data_2015 <- read.csv("jobindex_2015_20220924.csv")
data_2018 <- read.csv("jobindex_2018_20220924.csv")
data_train <- rbind(data_2006,data_2009,data_2012,data_2015,data_2018)
data_train <- data_train[,c(2:13)]
colnames(data_train) <-  c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP",
"EPD","HSP", "CSP", "OCC", "TOTAL_E")
write.csv(data_train, "All_20220924Truncated_distrivution.csv")
colnames(data_train) <-  c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP",
"EPD","HSP", "CSP", "OCC")
write.csv(data_train, "All_20220924Truncated_distrivution.csv")
library(boot)
library(sensitivity)
library(lhs)
library(ggplot2)
getwd()
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/R_Sampling_Multicorrelation")
data_train<-read.csv("AllCombinedResults_Uniform_20220924.csv")
###########################################################################################
#1 다중 회귀분석(Multi Linear Model=MLR) 모델 만들기
B_E = sample(1:nrow(data_train), 0.7*nrow(data_train))
train_data=data_train[B_E,]
test_data = data_train[-B_E,]
#2 모델 만들기
MLR_model = lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN
+ SHGC + LPD + COP
+ EPD + HSP + CSP + OCC, data = train_data)
View(data_train)
colnames(data_train) <-  c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP",
"EPD","HSP", "CSP", "OCC","TOTAL_E")
###########################################################################################
#1 다중 회귀분석(Multi Linear Model=MLR) 모델 만들기
B_E = sample(1:nrow(data_train), 0.7*nrow(data_train))
train_data=data_train[B_E,]
test_data = data_train[-B_E,]
#2 모델 만들기
MLR_model = lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN
+ SHGC + LPD + COP
+ EPD + HSP + CSP + OCC, data = train_data)
data_train<-read.csv("AllCombinedResults_Uniform_20220924.csv")
colnames(data_train) <-  c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP",
"EPD","HSP", "CSP", "OCC","TOTAL_E")
View(data_train)
###########################################################################################
#1 다중 회귀분석(Multi Linear Model=MLR) 모델 만들기
B_E = sample(1:nrow(data_train), 0.7*nrow(data_train))
train_data=data_train[B_E,]
test_data = data_train[-B_E,]
#2 모델 만들기
MLR_model = lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN
+ SHGC + LPD + COP
+ EPD + HSP + CSP + OCC, data = train_data)
#3 회귀선이 모델에 적합한지 검정
summary(MLR_model) #F-검정, 설명력 검정(R-square)
#4 모델 평가
pred = predict(MLR_model, test_data)
cor(pred, test_data$TOTAL_E)
#######################################################################################################################
#다중 공선성 계산
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/multicollinearity_Graph_Excel")
library(car)
vif(MLR_model)
library(sensitivity)
library(randomForest)
library(ggplot2)
library(nnet)
library(devtools)
library(neuralnet)
rm(list=ls())
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/Sensitivity Analysis")
getwd()
#data_train<- read.csv("U_AllCombinedResults_2006.csv")
#data_train<- read.csv("U_AllCombinedResults_2009.csv")
#data_train<- read.csv("U_AllCombinedResults_2012.csv")
#data_train<- read.csv("U_AllCombinedResults_2015.csv")
#data_train<- read.csv("U_AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_Uniform_20220924.csv")
colnames(data_train) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC", "TOTAL_E")
MLR_model =  lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = data_train)
summary(ANN_model)
##################################################################
#######SRRC 민감도 분석##########################################
srrc.result <- src(data_train[,c(1:12)],data_train[,13],rank=T)
srrc <- abs(srrc.result$SRRC[,1])
srrc <- data.frame(srrc)
rownames(srrc) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC")
#################################################################
######SoboL 민감도 분석#########################################
x1 <- data_train
set.seed(1)
x2  = data_train[sample(1:nrow(data_train)),]
Sa <- sobol(mode = MLR_model, X1 = x1, X2 = x2, order =2, nboot=500)
print(Sa) #Total sobol
Sobol <- print(Sa)
Sobol <- Sobol[c(1:12),1]
Sobol <- data.frame(Sobol)
rownames(Sobol) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC")
#################################################################
#######Meta 민감도 분석##########################################
library(tgp)
data_train_baby <- data_train[sample(nrow(data_train),500),]
meta <- sens(X=data_train_baby[,1:12], Z=data_train_baby[,13], nn.lhs=40, model=bgpllm)
meta <- colMeans(meta$sens$S)
Meta.results <- data.frame(meta)
################################################################
######SVI#######################################################
SVI_RESULT <- cbind(srrc,Sobol[1:12,1],Meta.results)
colSums(abs(SVI_RESULT))
################################################################
######SVI#######################################################
SVI_RESULT <- cbind(srrc,Sobol[1:12,1],Meta.results)
##################################################################
#######SRRC 민감도 분석##########################################
srrc.result <- src(data_train[,c(1:12)],data_train[,13],rank=T)
##################################################################
#######SRRC 민감도 분석##########################################
srrc.result <- src(data_train[,c(1:12)],data_train[,13],rank=T)
srrc <- abs(srrc.result$SRRC[,1])
srrc <- data.frame(srrc)
rownames(srrc) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC")
colnames(data_train) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC", "TOTAL_E")
MLR_model =  lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = data_train)
summary(ANN_model)
##################################################################
#######SRRC 민감도 분석##########################################
srrc.result <- src(data_train[,c(1:12)],data_train[,13],rank=T)
View(Meta.results)
View(Sobol)
TOTAL_Results <- cbind(Meta.results,Sobol)
#write.csv(TOTAL_Results,"Uniformed_sensitivity_2006.csv")
#write.csv(TOTAL_Results,"Uniformed_sensitivity_2009.csv")
#write.csv(TOTAL_Results,"Uniformed_sensitivity_2012.csv")
#write.csv(TOTAL_Results,"Uniformed_sensitivity_2015.csv")
#write.csv(TOTAL_Results,"Uniformed_sensitivity_2018.csv")
write.csv(TOTAL_Results,"All_Uniform_sensitivity_Results_20220924.csv")
rm(list=ls())
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/Sensitivity Analysis")
getwd()
#data_train<- read.csv("AllCombinedResults_2006.csv")
#data_train<- read.csv("AllCombinedResults_2009.csv")
#data_train<- read.csv("AllCombinedResults_2012.csv")
#data_train<- read.csv("AllCombinedResults_2015.csv")
#data_train<- read.csv("AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_All_Truncated_distribution.csv")
#data_train<- read.csv("U_AllCombinedResults_2006.csv")
#data_train<- read.csv("U_AllCombinedResults_2009.csv")
#data_train<- read.csv("U_AllCombinedResults_2012.csv")
#data_train<- read.csv("U_AllCombinedResults_2015.csv")
#data_train<- read.csv("U_AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_Uniform_20220924.csv")
colnames(data_train) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC", "TOTAL_E")
MLR_model =  lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = data_train)
summary(ANN_model)
##################################################################
#######SRRC 민감도 분석##########################################
srrc.result <- src(data_train[,c(1:12)],data_train[,13],rank=T)
srrc <- abs(srrc.result$SRRC[,1])
library(sensitivity)
library(randomForest)
library(ggplot2)
library(nnet)
library(devtools)
library(neuralnet)
rm(list=ls())
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/Sensitivity Analysis")
getwd()
#data_train<- read.csv("AllCombinedResults_2006.csv")
#data_train<- read.csv("AllCombinedResults_2009.csv")
#data_train<- read.csv("AllCombinedResults_2012.csv")
#data_train<- read.csv("AllCombinedResults_2015.csv")
#data_train<- read.csv("AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_All_Truncated_distribution.csv")
#data_train<- read.csv("U_AllCombinedResults_2006.csv")
#data_train<- read.csv("U_AllCombinedResults_2009.csv")
#data_train<- read.csv("U_AllCombinedResults_2012.csv")
#data_train<- read.csv("U_AllCombinedResults_2015.csv")
#data_train<- read.csv("U_AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_Uniform_20220924.csv")
colnames(data_train) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC", "TOTAL_E")
MLR_model =  lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = data_train)
summary(ANN_model)
##################################################################
#######SRRC 민감도 분석##########################################
srrc.result <- src(data_train[,c(1:12)],data_train[,13],rank=T)
srrc <- abs(srrc.result$SRRC[,1])
srrc <- data.frame(srrc)
rownames(srrc) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC")
View(srrc.result)
View(srrc.result)
View(srrc)
write.csv(srrc,"srrc.csv")
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/Sensitivity Analysis")
library(sensitivity)
library(randomForest)
library(ggplot2)
library(nnet)
library(devtools)
library(neuralnet)
rm(list=ls())
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/Sensitivity Analysis")
getwd()
#data_train<- read.csv("AllCombinedResults_2006.csv")
#data_train<- read.csv("AllCombinedResults_2009.csv")
#data_train<- read.csv("AllCombinedResults_2012.csv")
#data_train<- read.csv("AllCombinedResults_2015.csv")
#data_train<- read.csv("AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_Truncated_20220925.csv")
View(data_train)
data_train <- data_train[,c(2:13)]
View(data_train)
#data_train<- read.csv("AllCombinedResults_2006.csv")
#data_train<- read.csv("AllCombinedResults_2009.csv")
#data_train<- read.csv("AllCombinedResults_2012.csv")
#data_train<- read.csv("AllCombinedResults_2015.csv")
#data_train<- read.csv("AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_Truncated_20220925.csv")
colnames(data_train) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC", "TOTAL_E")
MLR_model =  lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = data_train)
ANN_model = neuralnet(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC,
data = data_train, hidden = 3, act.fact = "logistic", linear.output = FALSE)
ANN_model = neuralnet(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC,
data = data_train, hidden = 3, act.fact = "logistic", linear.output = FALSE)
ANN_model = neuralnet(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC,
data = data_train, hidden = 3, act.fct = "logistic", linear.output = FALSE)
plot(ANN_model)
ANN_model = neuralnet(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC,
data = data_train, hidden = 13, act.fct = "logistic", linear.output = FALSE)
plot(ANN_model)
#### MLR, ANN 모델 만들기
B_E = sample(1:nrow(data_train), 0.7*nrow(data_train))
train_data=data_train[B_E,]
test_data = data_train[-B_E,]
library(Metrics)
#4 모델 평가
pred = predict(MLR_model, test_data)
#4 모델 평가
pred_MLR = predict(MLR_model, test_data)
pred_ANN = predict(ANN_model, test_data)
#4 모델 평가
pred_MLR = predict(MLR_model, train_data)
rmse(pred_MLR, train_data)
rmse(pred_MLR, train_data$TOTAL_E)
pred_ANN = predict(ANN_model, train_data)
rmse(pred_ANN, train_data$TOTAL_E)
rmse(pred_ANN, train_data$TOTAL_E)
library(sensitivity)
library(randomForest)
library(Metrics)
library(ggplot2)
library(nnet)
library(devtools)
library(neuralnet)
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/Sensitivity Analysis")
#data_train<- read.csv("AllCombinedResults_2006.csv")
#data_train<- read.csv("AllCombinedResults_2009.csv")
#data_train<- read.csv("AllCombinedResults_2012.csv")
#data_train<- read.csv("AllCombinedResults_2015.csv")
#data_train<- read.csv("AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_Truncated_20220925.csv")
colnames(data_train) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC", "TOTAL_E")
#### MLR, ANN 모델 만들기
B_E = sample(1:nrow(data_train), 0.7*nrow(data_train))
train_data=data_train[B_E,]
test_data = data_train[-B_E,]
MLR_model =  lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = train_data)
ANN_model = neuralnet(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC,
data = train_data, hidden = 13, act.fct = "logistic", linear.output = FALSE)
plot(ANN_model)
#RMSE 구하기
pred_MLR = predict(MLR_model, train_data)
pred_ANN = predict(ANN_model, train_data)
rmse(pred_MLR, train_data$TOTAL_E)
rmse(pred_ANN, train_data$TOTAL_E)
View(ANN_model)
ANN_model = neuralnet(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC,
data = train_data, hidden = c(12, 12, 6), act.fct = "logistic", linear.output = FALSE)
plot(ANN_model)
#ANN Fit 확인
pred_ANN <- compute(ANN_model, train_data)
plot(train_data~pred_ANN$net.result)
library(neuralnet)
library(Metrics)
library(MASS)
data("Boston")
force(Boston)
data <- Boston
keeps <- c("crim","indus","nox","rm","age","dis","tax","ptratio","lstat","medv")
data<-data[keeps]
View(Boston)
data<-scale[data]
set.seed(2016)
n = nrow(data)
train <- sample(1:n, 400,FALSE)
f<-medv~ crim+indus + nox + rm + age + dis + tax + ptratio + lstat
fit<-neuralnet(f,
data = data[train,],
hidden = c(10,12,20),
algorithm = "rprop+",
err.fct ="sse",
act.fct = "logistic",
threshold = 0.1,
linear.output = TRUE)
pred<-compute(fit, data[-train, 1:9])
data[train,]
test <- data[train,]
View(test)
test <- data[train, 1:9]
library(sensitivity)
library(randomForest)
library(ggplot2)
library(nnet)
library(devtools)
library(neuralnet)
rm(list=ls())
setwd("C:/Users/ehdna/OneDrive - konkuk.ac.kr/학술발표대회/2022_동계학술발표대회/Sensitivity Analysis")
getwd()
#data_train<- read.csv("AllCombinedResults_2006.csv")
#data_train<- read.csv("AllCombinedResults_2009.csv")
#data_train<- read.csv("AllCombinedResults_2012.csv")
#data_train<- read.csv("AllCombinedResults_2015.csv")
#data_train<- read.csv("AllCombinedResults_2018.csv")
data_train<- read.csv("AllCombinedResults_Truncated_20220925.csv")
colnames(data_train) <- c("ROOF", "WALL", "FLOOR", "WIN", "SHGC", "LPD","HEATEFF","COP","EPD","HSP", "CSP", "OCC", "TOTAL_E")
MLR_model =  lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = data_train)
summary(MLR_model)
library(Metrics)
B_E = sample(1:nrow(data_train), 0.7*nrow(data_train))
train_data=data_train[B_E,]
test_data = data_train[-B_E,]
MLR_model =  lm(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = train_data)
ANN_model =neuralnet(TOTAL_E ~ ROOF + WALL + FLOOR + WIN + SHGC + LPD + HEATEFF + COP + EPD + HSP + CSP + OCC, data = train_data
, hidden=c(10,10,10), act.fct = "logistic", linear.output = FALSE)
summary(ANN_model)
Predict=compute(ANN_model,test_data)
Predict$net.result
View(Predict)
library(neuralnet)
library(Metrics)
library(MASS)
data("Boston")
data <- Boston
keeps <- c("crim","indus","nox","rm","age","dis","tax","ptratio","lstat","medv")
data<-data[keeps]
data<-scale[data]
set.seed(2016)
n = nrow(data)
train <- sample(1:n, 400,FALSE)
test <- data[train, 1:9]
f<-medv~ crim+indus + nox + rm + age + dis + tax + ptratio + lstat
fit<-neuralnet(f,
data = data[train,],
hidden = c(10,12,20),
algorithm = "rprop+",
err.fct ="sse",
act.fct = "logistic",
threshold = 0.1,
linear.output = TRUE)
library(Metrics)
library(MASS)
data("Boston")
data <- Boston
keeps <- c("crim","indus","nox","rm","age","dis","tax","ptratio","lstat","medv")
data<-data[keeps]
data<-scale[data]
set.seed(2016)
n = nrow(data)
train <- sample(1:n, 400,FALSE)
test <- data[train, 1:9]
f<-medv + crime ~ indus + nox + rm + age + dis + tax + ptratio + lstat
fit<-neuralnet(f,
data = data[train,],
hidden = c(10,12,20),
algorithm = "rprop+",
err.fct ="sse",
act.fct = "logistic",
threshold = 0.1,
linear.output = TRUE)
View(Boston)
data("Boston")
data <- Boston
keeps <- c("crim","indus","nox","rm","age","dis","tax","ptratio","lstat","medv")
data<-data[keeps]
data<-scale[data]
set.seed(2016)
n = nrow(data)
train <- sample(1:n, 400,FALSE)
test <- data[train, 1:9]
f<-medv + crim ~ indus + nox + rm + age + dis + tax + ptratio + lstat
fit<-neuralnet(f,
data = data[train,],
hidden = c(10,12,20),
algorithm = "rprop+",
err.fct ="sse",
act.fct = "logistic",
threshold = 0.1,
linear.output = TRUE)
pred<-compute(fit, data[-train, 1:9])
plot(data[-train,10]~pred$net.result)
plot(data[-train,9]~pred$net.result)
View(pred)
plot(data[-train,10]~pred$net.result)
View(fit)
